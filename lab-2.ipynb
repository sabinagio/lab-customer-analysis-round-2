{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the `marketing_customer_analysis.csv` file that you can find in the `files_for_lab` folder. Check out the `files_for_lab/about.md` to get more information if you are using the Online Excel.\n",
    "\n",
    "**Note**: For the next labs we will be using the same data file. Please save the code, so that you can re-use it later in the labs following this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Show the dataframe shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Standardize header names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "\n",
    "# Check header names & data\n",
    "print(df.columns)\n",
    "\n",
    "# Check what Unnamed: 0 column is\n",
    "print(df['Unnamed: 0'])\n",
    "\n",
    "# As the Unnamed: 0 column is identical to the index column, we can drop it\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the rest of the data\n",
    "print(df.head())\n",
    "\n",
    "# No other duplicates seen, so will proceed with removing the typo in one of the column names and changing the font to lowercase:\n",
    "df.rename(columns = {'EmploymentStatus': 'Employment Status'}, inplace = True)\n",
    "df.columns = df.columns.str.lower()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Which columns are numerical?\n",
    "\n",
    "- Customer Lifetime Value\n",
    "- Income\n",
    "- Monthly Premium Auto\n",
    "- Months Since Last Claim\n",
    "- Months Since Policy Inception\n",
    "- Number of Open Complaints\n",
    "- Number of Policies\n",
    "- Total Claim Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Which columns are categorical?\n",
    "\n",
    "All the remaining columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check and deal with `NaN` values.\n",
    "\n",
    "First off, we'll look at the amount of null values within the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = df.isna().sum()\n",
    "\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll compare this to the size of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_percentage = null_values * 100 / df.shape[0]\n",
    "print(null_values_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the vehicle type column has 1/2 missing values, we can drop that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('vehicle type', axis = 1, inplace = True)\n",
    "\n",
    "# Check that the drop was successful\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check how many rows have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dataframe = df[(df['state'].isna()) | (df['response'].isna()) \n",
    "| (df['months since last claim'].isna()) | (df['number of open complaints'].isna())\n",
    "| (df['vehicle class'].isna()) | (df['vehicle size'].isna())]\n",
    "\n",
    "print(null_dataframe.shape)\n",
    "print(null_dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the rows with at least one NaN value make up for ~16% of the dataframe, we can only remove very few of these rows. Let's check how many rows have NaN values in the categorical columns _state_ and _response_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dataframe = df[(df['state'].isna()) | (df['response'].isna())]\n",
    "print(null_dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we replace the NaN values with the modes of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_count = df['state'].value_counts()\n",
    "response_count = df['response'].value_counts()\n",
    "\n",
    "print(states_count)\n",
    "print(response_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could choose California as the default state, however Oregon & Arizona are relatively close contenders. Therefore, we'll drop the rows, which will automatically remove the null values in the _response_ column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['state'].isna() == False) | (df['response'].isna() == False)]\n",
    "\n",
    "#Check that the rows were droped\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to follow the same thinking for the _vehicle class_ and _vehicle size_ categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_class_count = df['vehicle class'].value_counts()\n",
    "vehicle_size_count = df['vehicle size'].value_counts()\n",
    "\n",
    "print(vehicle_class_count)\n",
    "print(vehicle_size_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it is more obvious what the mode for each columns is, so we'll replace the null values with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_class_mode = df['vehicle class'].mode()[0]\n",
    "vehicle_size_mode = df['vehicle size'].mode()[0]\n",
    "\n",
    "df['vehicle class'] = df['vehicle class'].fillna(vehicle_class_mode)\n",
    "df['vehicle size'] = df['vehicle size'].fillna(vehicle_size_mode)\n",
    "\n",
    "# Check if there are still NaN values in the columns\n",
    "print(df['vehicle class'].isna().sum())\n",
    "print(df['vehicle size'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the columns, we can replace the null values with the mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the columns have float/int data types:\n",
    "# print(df.dtypes)\n",
    "\n",
    "# Since the 'months since last claim' and 'number of open complaints' columns are already float64 types,\n",
    "# we can calculate their mean:\n",
    "mean_months = np.mean(df['months since last claim'])\n",
    "mean_open_complaints = np.mean(df['number of open complaints'])\n",
    "\n",
    "df['months since last claim'] = df['months since last claim'].fillna(mean_months)\n",
    "df['number of open complaints'] = df['number of open complaints'].fillna(mean_open_complaints)\n",
    "\n",
    "# Check if there are still NaN values in the columns\n",
    "print(df['months since last claim'].isna().sum())\n",
    "print(df['number of open complaints'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Datetime format - Extract the months from the dataset and store in a separate column. Then filter the data to show only the information for the first quarter , ie. January, February and March. Hint: If data from March does not exist, consider only January and February."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type in the column\n",
    "print(df['effective to date'].dtypes)\n",
    "\n",
    "# Convert to datetime format\n",
    "df['effective to date'] = pd.to_datetime(df['effective to date'], errors='coerce')\n",
    "\n",
    "# Check the data type again\n",
    "print(df['effective to date'].dtypes)\n",
    "print(df['effective to date'].head())\n",
    "\n",
    "# Extract the months from the dataset\n",
    "df['months'] = df.apply(lambda x: x['effective to date'].month, axis = 1)\n",
    "\n",
    "# Check the dataframe again\n",
    "df['months'].head()\n",
    "\n",
    "# Filter the data to show only first quarter info\n",
    "df = df[(df['months'] > 0) & (df['months'] < 4)]\n",
    "\n",
    "# Check that the data was filtered\n",
    "print(df['months'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put all the previously mentioned data transformations into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reading the data to test the function\n",
    "df_new = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "\n",
    "# will keep the most general items\n",
    "def big_clean(df):\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Clean NaN values & extra index column. Will replace all NaN by the mode in this case\n",
    "    for column in df.columns:\n",
    "        if (df[column].isna().sum() / df.shape[0]) > 0.5:\n",
    "            df.drop(column, axis = 1, inplace = True)\n",
    "        elif (df[column].isna().sum() > 0):\n",
    "            if df[column].dtypes == object:\n",
    "                df[column] = df[column].fillna(df[column].mode()[0])\n",
    "            else:\n",
    "                df[column] = df[column].fillna(np.mean(df[column]))\n",
    "    \n",
    "    return df.head(), df.isna().sum().sum()\n",
    "\n",
    "# Checking if the formula works\n",
    "big_clean(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
